{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notebook 1. (introduction, explanatory analysis, web scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* IPython command shell for interactive computing in multiple programming languages, originally developed for Python.\n",
    "* Powerful interactive shells (terminal and Qt-based).\n",
    "* A browser-based notebook with support for code, text, mathematical expressions, inline plots and rich media.\n",
    "* Support for interactive data visualization and use of GUI toolkits.\n",
    "* Flexible, embeddable interpreters to load into one's own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy - A collection of packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy - N-dimenional arrays\n",
    "* SciPy library - scientific computing\n",
    "* Matplotlib - for plotting\n",
    "* Sympy - symbolic math\n",
    "* pandas - data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=http://www.scipy.org/ width=1000 height=350></iframe>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=http://www.scipy.org/ width=1000 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit- learn - machine learning in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=http://scikit-learn.org/stable/ width=1000 height=400></iframe>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=http://scikit-learn.org/stable/ width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lists, dictionaries\n",
    "* NumPy arrays\n",
    "* DataFrame objects from Pandas package\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn, Pandas, NumPy and Matplotlib are all interlinked and work well together.\n",
    "\n",
    "Transferring between data formats is not always so trivial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* an N-dimensional array\n",
    "* fast, flexible container for large data sets in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy documentation: https://docs.scipy.org/doc/numpy-dev/user/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy cheat sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf width=1000 height=400></iframe>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multidimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2 = np.array([[1,2,3],[2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2, 3],\n       [2, 3, 4]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "array3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([7, 8, 9])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">How can I fetch the value 5 from the array above?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 4, 7])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed description about arrays:\n",
    "\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\n",
    "\n",
    "http://docs.scipy.org/doc/numpy/reference/arrays.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different attributes may have different types\n",
    "* Numpy (and pandas) will infer the type if none is specified\n",
    "* Incompatible types will lead to errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['1.25', 'hello', '42'], dtype='<U32')"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array4 = np.array([1.25, 'hello', 42])\n",
    "array4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U32 is a 32 character unicode string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('int32')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array5 = np.array([1, 2, 3, 4, 5])\n",
    "array5.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy infers reasonable data types. For example, a string cannot be interpretted as an int but an int can be interpretted as a string. Information is lost when you cast a float as an int but not vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">What data type will numpy infer if I make one number a float, a string?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.int32"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array5[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type can be set globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3, -1, -2,  0, 12, 10])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ 3, -1, -2, 0, 12.1, 10], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['1.25', '-9.6', '42'], dtype='<U4')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.unicode_)\n",
    "numeric_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type casting in python and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.25"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(numeric_strings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.25, -9.6 , 42.  ])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_strings.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Why is it important to be aware of data types?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U4'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUFuncTypeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\859208807.py\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mnumeric_strings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'1.25'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'-9.6'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'42'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0municode_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mfloats\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3.6\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m15.5\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mnumeric_strings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mfloats\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mUFuncTypeError\u001B[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U4'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "numeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.unicode_)\n",
    "floats = np.array([0, 3.6, 15.5], dtype=float)\n",
    "numeric_strings[0] + floats[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of numpy data types:\n",
    "\n",
    "http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html\n",
    "\n",
    "Pandas extends many numpy data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([(1, 2., 'Hello'), (2, 3., 'World')],\n      dtype=[('col0', '>i4'), ('col1', '>f4'), ('col2', '<U10')])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_array = np.array([(1, 2.0, 'Hello'), (2, 3.0, 'World')],dtype=[('col0', '>i4'), ('col1', '>f4'), ('col2', '|U10')])\n",
    "structured_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_array['col0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two records of three features:\n",
    "32-bit integer, 32-bit floating point number, 10-character string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from file to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO   # StringIO behaves like a file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([(b'M', 21, 72.), (b'F', 35, 58.), (b'F', 55, 66.)],\n      dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = StringIO('M 21 72\\n F 35 58\\n F 55 66')\n",
    "dat = np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n",
    "                     'formats': ('S1', 'i4', 'f4')})\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function np.loadtxt works in byte mode, in Python 2 this is the default string type. On the other hand, Python 3 uses unicode, and denotes byte-strings by b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([b'M', b'F', b'F'], dtype='|S1')"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([(b'M', 72.), (b'F', 58.), (b'F', 66.)],\n      dtype={'names':['gender','weight'], 'formats':['S1','<f4'], 'offsets':[0,5], 'itemsize':9})"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[['gender','weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 2.],\n       [3., 4.]])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = StringIO(\"1,0,2\\n3,0,4\")\n",
    "x = np.loadtxt(c, delimiter=',', usecols=(0,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data from local files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from file, we should pay attention to the access path of the file.\n",
    "\n",
    "We have to know in which folder the notebook is running and where is the file.\n",
    "\n",
    "Instead of absolute path, it is better to use relative paths, for more details [see here](https://www.computerhope.com/issues/ch001708.htm).\n",
    "\n",
    "* . : is the current directory\n",
    "\n",
    "* .. :  is the parent of the current directory.\n",
    "\n",
    "* / or \\: is the root of the current drive\n",
    "\n",
    "While doing the homework problems you should also use relative pathways while importing files, mimicking the folder structure given in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/bank.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\1802131246.py\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../Data/bank.csv\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m bank_data = np.loadtxt(f, dtype={'names': ('age', 'sex', 'region', 'income', 'married', 'children', 'car','save_acct', 'current_acct', 'mortgage', 'pep'),\n\u001B[0;32m      4\u001B[0m                                  'formats': ('i', 'S6', 'S10', 'f', 'S3', 'i2', 'S3', 'S3', 'S3', 'S3', 'S3')})\n\u001B[0;32m      5\u001B[0m \u001B[0mbank_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Data/bank.csv'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "f = open(\"../Data/bank.csv\",'r')\n",
    "bank_data = np.loadtxt(f, dtype={'names': ('age', 'sex', 'region', 'income', 'married', 'children', 'car','save_acct', 'current_acct', 'mortgage', 'pep'),\n",
    "                                 'formats': ('i', 'S6', 'S10', 'f', 'S3', 'i2', 'S3', 'S3', 'S3', 'S3', 'S3')})\n",
    "bank_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes of bank dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* age: age of customer in years (numeric)\n",
    "* sex: MALE / FEMALE\n",
    "* region: inner_city/rural/suburban/town\n",
    "* income: income of customer (numeric)\n",
    "* married: is the customer married (YES/NO)\n",
    "* children: number of children (numeric)\n",
    "* car: does the customer own a car (YES/NO)\n",
    "* save_acct: does the customer have a saving account (YES/NO)\n",
    "* current_acct: does the customer have a current account (YES/NO)\n",
    "* mortgage: does the customer have a mortgage (YES/NO)\n",
    "* pep: did the customer buy a PEP (Personal Equity Plan) after the last mailing (YES/NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bank_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\4059659803.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbank_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'age'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbank_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'income'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'bank_data' is not defined"
     ]
    }
   ],
   "source": [
    "x = bank_data['age']\n",
    "y = bank_data['income']\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('age (years)')\n",
    "plt.ylabel('income (dollars)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib documentation:\n",
    "    \n",
    "https://matplotlib.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib cheat sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=https://matplotlib.org/cheatsheets/cheatsheets.pdf width=1000 height=400></iframe>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=https://matplotlib.org/cheatsheets/cheatsheets.pdf width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects\n",
    "* One column of a DataFrame is a pandas series object. A series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas cheat sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf width=1000 height=400></iframe>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 MoviLens data files:\n",
    "* demographic information about the users (includes \"user_id\")\n",
    "* movie ratings (includes \"user_id\" and \"movie_id\")\n",
    "* information about the movies (includes \"movie_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the users data, using pandas read_csv() function. There is also read_json(), read_excel(), etc.\n",
    "\n",
    "We can take a look at the data file in the url.\n",
    "\n",
    "<span style=\"color:red\">What's the delimiter in this file?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  age sex     occupation zip_code\n0        1   24   M     technician    85711\n1        2   53   F          other    94043\n2        3   23   M         writer    32067\n3        4   24   M     technician    43537\n4        5   33   F          other    15213\n5        6   42   M      executive    98101\n6        7   57   M  administrator    91344\n7        8   36   M  administrator    05201\n8        9   29   M        student    01002\n9       10   53   M         lawyer    90703",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n      <td>94043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>32067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>43537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n      <td>15213</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>42</td>\n      <td>M</td>\n      <td>executive</td>\n      <td>98101</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>57</td>\n      <td>M</td>\n      <td>administrator</td>\n      <td>91344</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>36</td>\n      <td>M</td>\n      <td>administrator</td>\n      <td>05201</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>29</td>\n      <td>M</td>\n      <td>student</td>\n      <td>01002</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>53</td>\n      <td>M</td>\n      <td>lawyer</td>\n      <td>90703</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "\n",
    "users = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.user', \n",
    "    sep='|', names=u_cols)\n",
    "\n",
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['user_id', 'age', 'sex', 'occupation', 'zip_code'], dtype='object')"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that pandas implements numpy behind the scenes, leveraging numpy's array computation capabilities. You can also easily move between pandas and numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 24, 'M', 'technician', '85711'],\n       [2, 53, 'F', 'other', '94043'],\n       [3, 23, 'M', 'writer', '32067'],\n       ...,\n       [941, 20, 'M', 'student', '97229'],\n       [942, 48, 'F', 'librarian', '78209'],\n       [943, 22, 'M', 'student', '77841']], dtype=object)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_users = users.to_numpy()\n",
    "numpy_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       0   1  2              3      4\n0      1  24  M     technician  85711\n1      2  53  F          other  94043\n2      3  23  M         writer  32067\n3      4  24  M     technician  43537\n4      5  33  F          other  15213\n..   ...  .. ..            ...    ...\n938  939  26  F        student  33319\n939  940  32  M  administrator  02215\n940  941  20  M        student  97229\n941  942  48  F      librarian  78209\n942  943  22  M        student  77841\n\n[943 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n      <td>94043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>32067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>43537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n      <td>15213</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>939</td>\n      <td>26</td>\n      <td>F</td>\n      <td>student</td>\n      <td>33319</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>940</td>\n      <td>32</td>\n      <td>M</td>\n      <td>administrator</td>\n      <td>02215</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>941</td>\n      <td>20</td>\n      <td>M</td>\n      <td>student</td>\n      <td>97229</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>942</td>\n      <td>48</td>\n      <td>F</td>\n      <td>librarian</td>\n      <td>78209</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>943</td>\n      <td>22</td>\n      <td>M</td>\n      <td>student</td>\n      <td>77841</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(numpy_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "943"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load movie ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  movie_id  rating  unix_timestamp\n0      196       242       3       881250949\n1      186       302       3       891717742\n2       22       377       1       878887116\n3      244        51       2       880606923\n4      166       346       1       886397596",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>unix_timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n      <td>878887116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n      <td>880606923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n      <td>886397596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "    sep='\\t', names=r_cols)\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data about the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   movie_id              title release_date  video_release_date  \\\n0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n4         5     Copycat (1995)  01-Jan-1995                 NaN   \n\n                                            imdb_url  \n0  http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n1  http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n2  http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n3  http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n4  http://us.imdb.com/M/title-exact?Copycat%20(1995)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>video_release_date</th>\n      <th>imdb_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', \n",
    "            'video_release_date', 'imdb_url']\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.item', \n",
    "    sep='|', names=m_cols, usecols=range(5), encoding='latin-1')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                int64\n",
      "title                  object\n",
      "release_date           object\n",
      "video_release_date    float64\n",
      "imdb_url               object\n",
      "dtype: object\n",
      "          movie_id  video_release_date\n",
      "count  1682.000000                 0.0\n",
      "mean    841.500000                 NaN\n",
      "std     485.695893                 NaN\n",
      "min       1.000000                 NaN\n",
      "25%     421.250000                 NaN\n",
      "50%     841.500000                 NaN\n",
      "75%    1261.750000                 NaN\n",
      "max    1682.000000                 NaN\n"
     ]
    }
   ],
   "source": [
    "print(movies.dtypes)\n",
    "print(movies.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   movie_id             title release_date  \\\n0         1  Toy Story (1995)  01-Jan-1995   \n1         2  GoldenEye (1995)  01-Jan-1995   \n\n                                            imdb_url  \n0  http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n1  http://us.imdb.com/M/title-exact?GoldenEye%20(...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>imdb_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.drop(labels='video_release_date',axis=1,inplace=True)\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas users the same type casting syntax as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['title'] = movies['title'].astype(str)\n",
    "type(movies.at[0,'title']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas extends the numpy \"datetime64\" data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['release_date'] = pd.to_datetime(movies['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting, filtering, visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  age sex  occupation zip_code\n0        1   24   M  technician    85711\n1        2   53   F       other    94043\n2        3   23   M      writer    32067\n3        4   24   M  technician    43537\n4        5   33   F       other    15213",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n      <td>94043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>32067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>43537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n      <td>15213</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    technician\n1         other\n2        writer\n3    technician\n4         other\nName: occupation, dtype: object"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two ways to select a column\n",
    "users_col = users['occupation']\n",
    "users.occupation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['technician', 'other', 'writer', 'technician', 'other',\n       'executive', 'administrator', 'administrator', 'student', 'lawyer',\n       'other', 'other', 'educator', 'scientist', 'educator',\n       'entertainment', 'programmer', 'other', 'librarian', 'homemaker',\n       'writer', 'writer', 'artist', 'artist', 'engineer', 'engineer',\n       'librarian', 'writer', 'programmer', 'student', 'artist',\n       'student', 'student', 'administrator', 'homemaker', 'student',\n       'student', 'other', 'entertainment', 'scientist', 'engineer',\n       'administrator', 'librarian', 'technician', 'programmer',\n       'marketing', 'marketing', 'administrator', 'student', 'writer',\n       'educator', 'student', 'programmer', 'executive', 'programmer',\n       'librarian', 'none', 'programmer', 'educator', 'healthcare',\n       'engineer', 'administrator', 'marketing', 'educator', 'educator',\n       'student', 'student', 'student', 'engineer', 'engineer',\n       'scientist', 'administrator', 'student', 'scientist',\n       'entertainment', 'student', 'technician', 'administrator',\n       'administrator', 'administrator', 'student', 'programmer', 'other',\n       'executive', 'educator', 'administrator', 'administrator',\n       'librarian', 'administrator', 'educator', 'marketing',\n       'entertainment', 'executive', 'student', 'administrator', 'artist',\n       'artist', 'executive', 'student', 'executive', 'student',\n       'programmer', 'student', 'student', 'engineer', 'retired',\n       'scientist', 'educator', 'other', 'student', 'engineer',\n       'salesman', 'executive', 'programmer', 'engineer', 'healthcare',\n       'student', 'administrator', 'programmer', 'other', 'librarian',\n       'writer', 'artist', 'student', 'lawyer', 'lawyer', 'none',\n       'marketing', 'marketing', 'none', 'administrator', 'other',\n       'engineer', 'programmer', 'student', 'other', 'educator', 'doctor',\n       'student', 'student', 'programmer', 'other', 'technician',\n       'programmer', 'entertainment', 'artist', 'librarian', 'engineer',\n       'marketing', 'artist', 'administrator', 'educator', 'student',\n       'student', 'other', 'educator', 'engineer', 'educator', 'student',\n       'programmer', 'lawyer', 'artist', 'administrator', 'healthcare',\n       'other', 'educator', 'other', 'other', 'other', 'healthcare',\n       'educator', 'marketing', 'other', 'administrator', 'scientist',\n       'scientist', 'programmer', 'other', 'entertainment',\n       'administrator', 'executive', 'programmer', 'scientist',\n       'librarian', 'librarian', 'executive', 'educator', 'student',\n       'artist', 'administrator', 'administrator', 'educator', 'student',\n       'administrator', 'scientist', 'writer', 'technician', 'student',\n       'writer', 'programmer', 'writer', 'educator', 'student',\n       'librarian', 'lawyer', 'student', 'marketing', 'engineer',\n       'educator', 'engineer', 'salesman', 'educator', 'executive',\n       'librarian', 'programmer', 'engineer', 'other', 'administrator',\n       'programmer', 'librarian', 'student', 'programmer', 'student',\n       'educator', 'administrator', 'student', 'executive', 'student',\n       'librarian', 'student', 'librarian', 'scientist', 'engineer',\n       'retired', 'educator', 'writer', 'administrator', 'administrator',\n       'artist', 'educator', 'student', 'educator', 'educator',\n       'technician', 'student', 'student', 'engineer', 'student',\n       'student', 'executive', 'doctor', 'engineer', 'librarian',\n       'educator', 'entertainment', 'none', 'student', 'student',\n       'student', 'artist', 'administrator', 'student', 'programmer',\n       'writer', 'executive', 'administrator', 'engineer', 'engineer',\n       'librarian', 'student', 'engineer', 'scientist', 'other',\n       'student', 'engineer', 'student', 'administrator', 'librarian',\n       'programmer', 'librarian', 'student', 'administrator',\n       'programmer', 'executive', 'programmer', 'student', 'salesman',\n       'marketing', 'none', 'engineer', 'student', 'programmer', 'writer',\n       'technician', 'educator', 'administrator', 'educator', 'executive',\n       'doctor', 'programmer', 'student', 'educator', 'student',\n       'student', 'programmer', 'other', 'student', 'retired',\n       'scientist', 'educator', 'technician', 'other', 'marketing',\n       'student', 'educator', 'other', 'administrator', 'retired',\n       'programmer', 'student', 'educator', 'student', 'student',\n       'student', 'technician', 'administrator', 'student',\n       'administrator', 'educator', 'educator', 'entertainment',\n       'student', 'other', 'librarian', 'executive', 'salesman',\n       'scientist', 'librarian', 'lawyer', 'engineer', 'student', 'other',\n       'engineer', 'librarian', 'librarian', 'other', 'student',\n       'student', 'retired', 'student', 'educator', 'programmer',\n       'scientist', 'librarian', 'student', 'homemaker', 'executive',\n       'educator', 'student', 'other', 'student', 'homemaker', 'student',\n       'engineer', 'lawyer', 'student', 'student', 'student', 'student',\n       'writer', 'engineer', 'student', 'other', 'executive',\n       'entertainment', 'other', 'student', 'student', 'programmer',\n       'engineer', 'artist', 'engineer', 'administrator', 'programmer',\n       'writer', 'salesman', 'entertainment', 'other', 'writer', 'writer',\n       'student', 'writer', 'student', 'administrator', 'other',\n       'engineer', 'student', 'other', 'other', 'administrator',\n       'healthcare', 'engineer', 'other', 'programmer', 'healthcare',\n       'educator', 'engineer', 'student', 'administrator', 'artist',\n       'educator', 'educator', 'educator', 'programmer', 'educator',\n       'student', 'other', 'none', 'lawyer', 'educator', 'programmer',\n       'entertainment', 'other', 'marketing', 'student', 'educator',\n       'doctor', 'student', 'student', 'scientist', 'marketing',\n       'entertainment', 'artist', 'student', 'engineer', 'administrator',\n       'other', 'administrator', 'administrator', 'other', 'technician',\n       'student', 'salesman', 'lawyer', 'writer', 'educator',\n       'administrator', 'entertainment', 'librarian', 'educator',\n       'student', 'administrator', 'student', 'other', 'administrator',\n       'technician', 'salesman', 'technician', 'student', 'other',\n       'student', 'student', 'healthcare', 'writer', 'other', 'student',\n       'engineer', 'engineer', 'educator', 'programmer', 'student',\n       'student', 'student', 'executive', 'programmer', 'student',\n       'student', 'other', 'educator', 'retired', 'retired', 'student',\n       'scientist', 'student', 'educator', 'educator', 'engineer',\n       'technician', 'other', 'artist', 'writer', 'educator', 'engineer',\n       'administrator', 'engineer', 'student', 'student', 'writer',\n       'programmer', 'administrator', 'student', 'student', 'writer',\n       'writer', 'other', 'programmer', 'writer', 'marketing',\n       'administrator', 'other', 'student', 'other', 'administrator',\n       'programmer', 'marketing', 'librarian', 'student', 'writer',\n       'other', 'healthcare', 'student', 'engineer', 'administrator',\n       'educator', 'administrator', 'marketing', 'librarian', 'student',\n       'administrator', 'engineer', 'salesman', 'student', 'librarian',\n       'student', 'educator', 'engineer', 'engineer', 'scientist',\n       'administrator', 'engineer', 'student', 'student', 'scientist',\n       'other', 'technician', 'executive', 'educator', 'writer',\n       'scientist', 'student', 'programmer', 'other', 'educator',\n       'scientist', 'educator', 'educator', 'writer', 'writer',\n       'executive', 'student', 'engineer', 'administrator', 'librarian',\n       'retired', 'student', 'student', 'entertainment', 'educator',\n       'educator', 'educator', 'artist', 'educator', 'retired',\n       'educator', 'marketing', 'executive', 'student', 'administrator',\n       'educator', 'student', 'other', 'student', 'engineer', 'student',\n       'librarian', 'student', 'other', 'student', 'lawyer', 'educator',\n       'librarian', 'student', 'educator', 'educator', 'programmer',\n       'artist', 'other', 'marketing', 'student', 'programmer', 'artist',\n       'other', 'programmer', 'educator', 'engineer', 'programmer',\n       'healthcare', 'other', 'student', 'student', 'librarian',\n       'educator', 'marketing', 'educator', 'educator', 'scientist',\n       'writer', 'student', 'student', 'writer', 'student', 'programmer',\n       'educator', 'student', 'programmer', 'scientist', 'engineer',\n       'none', 'other', 'healthcare', 'student', 'student', 'programmer',\n       'engineer', 'other', 'educator', 'other', 'engineer', 'librarian',\n       'student', 'student', 'student', 'scientist', 'retired',\n       'programmer', 'student', 'educator', 'engineer', 'student',\n       'engineer', 'retired', 'other', 'executive', 'student',\n       'healthcare', 'educator', 'none', 'programmer', 'educator',\n       'student', 'programmer', 'librarian', 'other', 'engineer',\n       'administrator', 'administrator', 'librarian', 'writer', 'other',\n       'technician', 'programmer', 'administrator', 'educator', 'student',\n       'other', 'programmer', 'other', 'educator', 'student', 'lawyer',\n       'marketing', 'programmer', 'librarian', 'student', 'librarian',\n       'educator', 'healthcare', 'administrator', 'other', 'salesman',\n       'educator', 'engineer', 'healthcare', 'programmer', 'writer',\n       'other', 'other', 'programmer', 'other', 'student', 'librarian',\n       'other', 'educator', 'librarian', 'student', 'student',\n       'librarian', 'homemaker', 'other', 'student', 'student', 'student',\n       'other', 'engineer', 'technician', 'administrator', 'technician',\n       'technician', 'other', 'administrator', 'entertainment',\n       'homemaker', 'executive', 'executive', 'student', 'administrator',\n       'student', 'executive', 'student', 'scientist', 'educator',\n       'other', 'other', 'other', 'healthcare', 'writer', 'programmer',\n       'technician', 'technician', 'educator', 'writer', 'student',\n       'programmer', 'marketing', 'writer', 'engineer', 'other',\n       'administrator', 'other', 'administrator', 'other', 'retired',\n       'salesman', 'librarian', 'educator', 'none', 'student', 'student',\n       'student', 'other', 'student', 'administrator', 'scientist',\n       'educator', 'student', 'other', 'engineer', 'administrator',\n       'executive', 'student', 'student', 'writer', 'student', 'student',\n       'executive', 'librarian', 'programmer', 'student', 'student',\n       'programmer', 'student', 'artist', 'marketing', 'administrator',\n       'engineer', 'engineer', 'student', 'administrator', 'other',\n       'technician', 'educator', 'programmer', 'student', 'educator',\n       'programmer', 'writer', 'other', 'writer', 'administrator',\n       'programmer', 'writer', 'administrator', 'administrator',\n       'educator', 'other', 'marketing', 'healthcare', 'salesman',\n       'marketing', 'other', 'educator', 'technician', 'student', 'other',\n       'other', 'other', 'student', 'librarian', 'administrator',\n       'student', 'engineer', 'librarian', 'artist', 'other', 'engineer',\n       'artist', 'engineer', 'librarian', 'writer', 'programmer', 'other',\n       'technician', 'writer', 'other', 'executive', 'artist', 'artist',\n       'student', 'entertainment', 'artist', 'doctor', 'writer',\n       'librarian', 'engineer', 'doctor', 'lawyer', 'student', 'engineer',\n       'student', 'technician', 'other', 'administrator', 'writer',\n       'student', 'librarian', 'marketing', 'administrator', 'educator',\n       'other', 'retired', 'student', 'executive', 'student',\n       'programmer', 'artist', 'other', 'scientist', 'programmer',\n       'student', 'student', 'executive', 'student', 'administrator',\n       'scientist', 'student', 'other', 'other', 'educator',\n       'administrator', 'student', 'marketing', 'engineer', 'librarian',\n       'engineer', 'other', 'student', 'student', 'scientist',\n       'technician', 'student', 'administrator', 'other', 'student',\n       'educator', 'librarian', 'writer', 'other', 'homemaker', 'other',\n       'retired', 'executive', 'artist', 'educator', 'student', 'other',\n       'librarian', 'other', 'librarian', 'educator', 'healthcare',\n       'writer', 'other', 'student', 'other', 'entertainment', 'engineer',\n       'student', 'scientist', 'other', 'artist', 'student',\n       'administrator', 'student', 'other', 'salesman', 'entertainment',\n       'programmer', 'student', 'scientist', 'scientist', 'educator',\n       'educator', 'student', 'engineer', 'doctor', 'other', 'educator',\n       'technician', 'student', 'administrator', 'student', 'librarian',\n       'student'], dtype=object)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_col.to_list()\n",
    "users_col.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   occupation sex\n0  technician   M\n1       other   F\n2      writer   M\n3  technician   M\n4       other   F",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>occupation</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>technician</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>other</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>writer</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>technician</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>other</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_you_want = ['occupation', 'sex']\n",
    "users[columns_you_want].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'technician'"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a single value, .loc and .iloc are two indexing methods\n",
    "users.at[0,'occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "user_id                1\nage                   24\nsex                    M\noccupation    technician\nzip_code           85711\nName: 0, dtype: object"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a row\n",
    "users.loc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with pandas\n",
    "\n",
    "Notice that pandas implements matplotlib behind the scenes too, so you can use commands such as plt.title() in combination with your pandas plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\1573509121.py\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0musers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Distribution of user age'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPc0lEQVR4nO3df4zcdV7H8efbcp5c94RiuU2ljYtJgwdUesemh8GYXdCjd5jrmYgpwUuJmPpHL4GkiRZNvDOGhH+KmiAXqyAk3LFW7pAG5JTU25AzItdynG0pDc11xVJsvbPALRJ0ubd/zLdhbpl2Z+f3fPb5SDYz38/3O/N5zXb31e98Z+a7kZlIksryY/0OIEnqPMtdkgpkuUtSgSx3SSqQ5S5JBTqv3wEAVq5cmWNjYz2d86233mL58uU9nbMThjU3DG92c/eWuZu3f//+72XmxY3WDUS5j42NsW/fvp7OOT09zcTERE/n7IRhzQ3Dm93cvWXu5kXEv59tnYdlJKlAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQAPxCVUNj7EdT7Z82+3r5ri1xdvP3H1jy/NKS5F77pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBVowXKPiDUR8Y2IOBwRhyLi9mr8ooh4OiJeri5X1N3mzog4GhFHIuKGbj4ASdL7NbPnPgdsz8yPAtcA2yLicmAHsDcz1wJ7q2WqdZuBK4CNwH0Rsawb4SVJjS1Y7pn5WmY+X13/AXAYuATYBDxUbfYQ8Nnq+iZgKjPfycxjwFFgQ4dzS5LOITKz+Y0jxoBngCuBVzLzwrp1pzNzRUTcCzybmQ9X4/cDT2Xmo/PuayuwFWB0dPTqqampNh/K4szOzjIyMtLTOTuh37kPvPpGy7cdPR9Ovt3abdddckHL87ar39/zVpm7t/qRe3Jycn9mjjda1/TfUI2IEeCrwB2Z+WZEnHXTBmPv+x8kM3cBuwDGx8dzYmKi2SgdMT09Ta/n7IR+5271b6BC7W+o7jzQ2p/tnbllouV529Xv73mrzN1bg5a7qXfLRMQHqBX7lzPza9XwyYhYVa1fBZyqxo8Da+puvho40Zm4kqRmLLgbFbVd9PuBw5l5T92qPcAW4O7q8vG68a9ExD3ATwNrgec6GXqpG2tj71nS0tDMc+Rrgc8BByLihWrs96mV+u6IuA14BbgJIDMPRcRu4EVq77TZlpnvdjq4JOnsFiz3zPwmjY+jA1x/ltvcBdzVRi5JUhv8hKokFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKtCC5R4RD0TEqYg4WDf2xYh4NSJeqL4+Xbfuzog4GhFHIuKGbgWXJJ1dM3vuDwIbG4z/SWaur77+HiAiLgc2A1dUt7kvIpZ1KqwkqTkLlntmPgP8d5P3twmYysx3MvMYcBTY0EY+SVILIjMX3ihiDHgiM6+slr8I3Aq8CewDtmfm6Yi4F3g2Mx+utrsfeCozH21wn1uBrQCjo6NXT01NdeLxNG12dpaRkZGeztkJs7OzHHvj3X7HaMno+XDy7dZuu+6SCzobZhGG+WfF3L3Tj9yTk5P7M3O80brzWrzPLwF/DGR1uRP4LSAabNvwf4/M3AXsAhgfH8+JiYkWo7RmenqaXs/ZCdPT0+z85lv9jtGS7evm2HmgtR+5mVsmOhtmEYb5Z8XcvTNouVt6t0xmnszMdzPzh8Bf8t6hl+PAmrpNVwMn2osoSVqslso9IlbVLf4acOadNHuAzRHxwYi4FFgLPNdeREnSYi34HDkiHgEmgJURcRz4AjAREeupHXKZAX4HIDMPRcRu4EVgDtiWmcN5gFiShtiC5Z6ZNzcYvv8c298F3NVOKElSe/yEqiQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCrTgH8iWBsHYjif7NveDG5f3bW6pVe65S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAL5VkhpAQdefYNb+/BWzJm7b+z5nCqHe+6SVCDLXZIKZLlLUoE85i4NqHZPubB93VzLrxV4vH/4uecuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCrRguUfEAxFxKiIO1o1dFBFPR8TL1eWKunV3RsTRiDgSETd0K7gk6eya2XN/ENg4b2wHsDcz1wJ7q2Ui4nJgM3BFdZv7ImJZx9JKkpqy4IeYMvOZiBibN7wJmKiuPwRMA79XjU9l5jvAsYg4CmwA/qVDeQdKP/6u5/Z1c/jZM0kLicxceKNauT+RmVdWy69n5oV1609n5oqIuBd4NjMfrsbvB57KzEcb3OdWYCvA6Ojo1VNTUx14OM2bnZ1lZGSkrfs48OobHUrTvNHz4eTbPZ+2I4Y1+1LMve6SCzobZhE68bvZD/3IPTk5uT8zxxut6/QuYDQYa/i/R2buAnYBjI+P58TERIejnNv09DTtztmP08BuXzfHzgPDuec+rNmXYu6ZWyY6G2YROvG72Q+DlrvVd8ucjIhVANXlqWr8OLCmbrvVwInW40mSWtFque8BtlTXtwCP141vjogPRsSlwFrgufYiSpIWa8HnbBHxCLUXT1dGxHHgC8DdwO6IuA14BbgJIDMPRcRu4EVgDtiWme92Kbsk6SyaebfMzWdZdf1Ztr8LuKudUJKk9vgJVUkqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUoPPauXFEzAA/AN4F5jJzPCIuAv4GGANmgN/IzNPtxZQkLUYn9twnM3N9Zo5XyzuAvZm5FthbLUuSeqgbh2U2AQ9V1x8CPtuFOSRJ5xCZ2fqNI44Bp4EE/iIzd0XE65l5Yd02pzNzRYPbbgW2AoyOjl49NTXVco5WzM7OMjIy0tZ9HHj1jQ6lad7o+XDy7Z5P2xHDmn0p5l53yQWdDbMInfjd7Id+5J6cnNxfd9TkR7R1zB24NjNPRMRHgKcj4qVmb5iZu4BdAOPj4zkxMdFmlMWZnp6m3Tlv3fFkZ8IswvZ1c+w80O4/W38Ma/almHvmlonOhlmETvxu9sOg5W7rsExmnqguTwGPARuAkxGxCqC6PNVuSEnS4rRc7hGxPCI+fOY68EngILAH2FJttgV4vN2QkqTFaee55ijwWEScuZ+vZObXI+JbwO6IuA14Bbip/ZiSpMVoudwz87vAVQ3Gvw9c304oSVJ7/ISqJBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFGr4TZkjqurE+nDcJYObuG/syb4ncc5ekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgrkuWUkDYyxHU+yfd0ct/b43DYlntPGPXdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCFXFWyLEWziDXjzPPSRpMrXTIfK12SrfOSOmeuyQVyHKXpAJZ7pJUIMtdkgrUtXKPiI0RcSQijkbEjm7NI0l6v66Ue0QsA/4c+BRwOXBzRFzejbkkSe/XrT33DcDRzPxuZv4vMAVs6tJckqR5IjM7f6cRvw5szMzfrpY/B3wiMz9ft81WYGu1eBlwpONBzm0l8L0ez9kJw5obhje7uXvL3M37mcy8uNGKbn2IKRqM/cj/Ipm5C9jVpfkXFBH7MnO8X/O3alhzw/BmN3dvmbszunVY5jiwpm55NXCiS3NJkubpVrl/C1gbEZdGxI8Dm4E9XZpLkjRPVw7LZOZcRHwe+AdgGfBAZh7qxlxt6NshoTYNa24Y3uzm7i1zd0BXXlCVJPWXn1CVpAJZ7pJUoCVR7hHxQEScioiDdWMXRcTTEfFydbminxkbiYg1EfGNiDgcEYci4vZqfKCzR8RPRMRzEfGdKvcfVeMDnfuMiFgWEd+OiCeq5YHPHREzEXEgIl6IiH3V2DDkvjAiHo2Il6qf818YktyXVd/rM19vRsQdg5R9SZQ78CCwcd7YDmBvZq4F9lbLg2YO2J6ZHwWuAbZVp3EY9OzvANdl5lXAemBjRFzD4Oc+43bgcN3ysOSezMz1de+1HobcfwZ8PTN/DriK2vd94HNn5pHqe70euBr4H+AxBil7Zi6JL2AMOFi3fARYVV1fBRzpd8YmHsPjwK8MU3bgQ8DzwCeGITe1z2TsBa4DnhiWnxVgBlg5b2ygcwM/CRyjemPHsORu8Dg+CfzzoGVfKnvujYxm5msA1eVH+pznnCJiDPgY8K8MQfbq0MYLwCng6cwcitzAnwK/C/ywbmwYcifwjxGxvzq1Bwx+7p8F/gv46+ow2F9FxHIGP/d8m4FHqusDk30pl/vQiIgR4KvAHZn5Zr/zNCMz383aU9bVwIaIuLLPkRYUEb8KnMrM/f3O0oJrM/Pj1M7Eui0ifqnfgZpwHvBx4EuZ+THgLQbwEMy5VB/S/Azwt/3OMt9SLveTEbEKoLo81ec8DUXEB6gV+5cz82vV8FBkB8jM14Fpaq95DHrua4HPRMQMtTOZXhcRDzP4ucnME9XlKWrHfjcw+LmPA8erZ3UAj1Ir+0HPXe9TwPOZebJaHpjsS7nc9wBbqutbqB3PHigREcD9wOHMvKdu1UBnj4iLI+LC6vr5wC8DLzHguTPzzsxcnZlj1J5q/1Nm/iYDnjsilkfEh89cp3YM+CADnjsz/xP4j4i4rBq6HniRAc89z828d0gGBil7v1+M6NELHo8ArwH/R21v4Tbgp6i9cPZydXlRv3M2yP2L1I6l/hvwQvX16UHPDvw88O0q90HgD6vxgc497zFM8N4LqgOdm9qx6+9UX4eAPxiG3FXG9cC+6mfl74AVw5C7yv4h4PvABXVjA5Pd0w9IUoGW8mEZSSqW5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIK9P9piBqU5nCB/wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "users.age.hist()\n",
    "plt.title('Distribution of user age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a slice of the dataframe based on certain criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_over_25 = users[users.age > 25]\n",
    "users_over_25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[(users.age == 40) & (users.sex == 'M')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these techniques to answer questions such as, whats the average age of female programmers in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select users who are both female and programmers\n",
    "selected_users = users[(users.sex == 'F') & \n",
    "                       (users.occupation == 'programmer')]\n",
    "\n",
    "# show statistic summary\n",
    "print(selected_users.describe())\n",
    "\n",
    "# or use the build in mean() function\n",
    "print(selected_users.age.mean())\n",
    "print(selected_users['age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split-apply-combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splitting the data into groups based on some criteria.\n",
    "* Applying a function to each group independently.\n",
    "* Combining the results into a data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average rating of users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = ratings.groupby(['user_id'])['rating'].mean() #or sum(), count(), median(), etc.\n",
    "user_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">How many rows are there in \"user_mean\"?</span>\n",
    "<span style=\"color:red\">How many rows would there be if I grouped by \"movie_id\" instead?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\3071929385.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muser_mean\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmovies\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'user_mean' is not defined"
     ]
    }
   ],
   "source": [
    "len(user_mean)\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way using the apply() method to apply a function\n",
    "\n",
    "<span style=\"color:red\">What does x refer to?</span>\n",
    "\n",
    "<span style=\"color:red\">Why is this syntax useful?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "movie_id\n1    3.878319\n2    3.206107\n3    3.033333\n4    3.550239\n5    3.302326\nName: rating, dtype: float64"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_mean = ratings.groupby(['movie_id'])['rating']\n",
    "average_ratings = movie_mean.apply(lambda x: x.mean())\n",
    "average_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the highest rated movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "movie_id\n814     5.0\n1599    5.0\n1201    5.0\n1122    5.0\n1653    5.0\n1293    5.0\n1500    5.0\n1189    5.0\n1536    5.0\nName: rating, dtype: float64"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_ratings.sort_values(ascending = False)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     movie_id                          title release_date  \\\n813       814  Great Day in Harlem, A (1994)   1994-01-01   \n\n                                              imdb_url  \n813  http://us.imdb.com/M/title-exact?Great%20Day%2...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>imdb_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>Great Day in Harlem, A (1994)</td>\n      <td>1994-01-01</td>\n      <td>http://us.imdb.com/M/title-exact?Great%20Day%2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search df based on single value\n",
    "movies[movies['movie_id']==814]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "      movie_id                                              title  \\\n813        814                      Great Day in Harlem, A (1994)   \n1598      1599                      Someone Else's America (1995)   \n1200      1201         Marlene Dietrich: Shadow and Light (1996)    \n1121      1122                     They Made Me a Criminal (1939)   \n1652      1653  Entertaining Angels: The Dorothy Day Story (1996)   \n\n     release_date                                           imdb_url  rating  \n813    1994-01-01  http://us.imdb.com/M/title-exact?Great%20Day%2...     5.0  \n1598   1996-05-10  http://us.imdb.com/M/title-exact?Someone%20Els...     5.0  \n1200   1996-04-02  http://us.imdb.com/M/title-exact?Marlene%20Die...     5.0  \n1121   1939-01-01  http://us.imdb.com/M/title-exact?They%20Made%2...     5.0  \n1652   1996-09-27  http://us.imdb.com/M/title-exact?Entertaining%...     5.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>imdb_url</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>Great Day in Harlem, A (1994)</td>\n      <td>1994-01-01</td>\n      <td>http://us.imdb.com/M/title-exact?Great%20Day%2...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>1599</td>\n      <td>Someone Else's America (1995)</td>\n      <td>1996-05-10</td>\n      <td>http://us.imdb.com/M/title-exact?Someone%20Els...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1200</th>\n      <td>1201</td>\n      <td>Marlene Dietrich: Shadow and Light (1996)</td>\n      <td>1996-04-02</td>\n      <td>http://us.imdb.com/M/title-exact?Marlene%20Die...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>1122</td>\n      <td>They Made Me a Criminal (1939)</td>\n      <td>1939-01-01</td>\n      <td>http://us.imdb.com/M/title-exact?They%20Made%2...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1652</th>\n      <td>1653</td>\n      <td>Entertaining Angels: The Dorothy Day Story (1996)</td>\n      <td>1996-09-27</td>\n      <td>http://us.imdb.com/M/title-exact?Entertaining%...</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way, use pd.merge() to join to dataframes\n",
    "\n",
    "print(type(average_ratings))\n",
    "avg_ratings_df = pd.DataFrame(average_ratings)\n",
    "merged = movies.merge(avg_ratings_df, on='movie_id')\n",
    "merged.sort_values(by='rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Urllib: the most basic webscraping package \n",
    "- BeautifulSoup: Lightning fast static web page processing\n",
    "- Selenium: To manipulate, test and scrape dynamic HTML web pages. It is able to use the elements of the user interface, for example fill in forms, check the checkboxes and so on...\n",
    "\n",
    "**Strategy:** \n",
    "1. Extract the data from the dynamic html with Selenium \n",
    "2. Turn the data into a beautiful soup object to process the html with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful and fair (copyright, license, media law, server overloading, etc.)!**\n",
    "- the robots.txt file, generally located at the root of a website, communicates to webcrawlers about what is off limits to scrape, protecting their intellectual property\n",
    "- it is not a legal requirement but a widely used convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For web scraping we should have a basic understanding of HTML tags!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML, just the basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags, Elements, Attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tag: < something between angle brackets > <br>\n",
    "Some important tags:\n",
    "- <div>                   sections\n",
    "- <h1> - <h6>             headings\n",
    "- <p>, <pre>              paragraphs\n",
    "- <ul>, <ol>, <li>        lists\n",
    "- <a>                     links\n",
    "- <img>                   images\n",
    "- <table>                 tables\n",
    "- <tr>                    rows within tables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Element: It begins with a tag, ends with a tag, and it contains the text between them aswell.\n",
    "for example:\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "    \n",
    "        <h1> Fake header on a fake website </h1>\n",
    "    \n",
    "        <p> color='red' This thing with it's tags is an element. </p>\n",
    "        \n",
    "    </head>\n",
    "    \n",
    "</html>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attributes: Contains aditional information about the tags (in general they are in the opening of the tag).\n",
    "for example:\n",
    "\n",
    "- <img src=\"picture.png\"> src is an attribute with the value \"picture\"\n",
    "- <p color=\"red\"> color is an attribute\n",
    "- <div id=\"scrapeMe\"> id is an attribute\n",
    "- <a href='http://thisisalink.com' a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about HTML\n",
    "\n",
    "https://www.w3schools.com/html/html_basic.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most of the time when we scrape html pages we locate the information by it's tags and attributes. The most important tags in this manner are id and class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOM tree (Document Object Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DomTree0](https://media.licdn.com/dms/image/C4D22AQH_rjlNORWwqQ/feedshare-shrink_2048_1536/0/1676362097908?e=1679529600&v=beta&t=xeHCbIrxWWkZ3Me-PiRuIA74GImkuTN1wyLN02VUPTw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DomTree](https://media.licdn.com/dms/image/C4D22AQGc3tTlAY6x7Q/feedshare-shrink_2048_1536/0/1676362027964?e=1679529600&v=beta&t=Uf0oElJllBNmQv6N1XvtDzQrsAlhDlN36E7yIoEuPbY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The inner HTML of  the elements are of the same nature as the whole html page. We can use the same methods to locate an information for example in a div as we do in the html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping static webpages using Beautifulsoup and Urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading an entire webpage as a string using Urllib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=https://www.crummy.com/software/BeautifulSoup/ width=1000 height=400></iframe>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the website we will scrape first\n",
    "# %%capture --no-display\n",
    "HTML('<iframe src=https://www.crummy.com/software/BeautifulSoup/ width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"/nb/themes/Default/nb.css\">\n",
      "<meta name=\"Description\" content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\">\n",
      "<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\n",
      "<meta name=\"author\" content=\"Leonard Richardson\">\n",
      "</head>\n",
      "<body bgcolor=\"white\" text=\"black\" link=\"blue\" vlink=\"660066\" alink=\"red\">\n",
      "<style>\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "</style>\t\t   \n",
      "\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"><br />\n",
      "\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a\n",
      "href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "\n",
      "<div align=\"center\">\n",
      "\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "\n",
      "</div>\n",
      "\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "<ol>\n",
      "\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "<li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "<li>Beautiful Soup sits on top of popular Python parsers like <a\n",
      "href=\"http://lxml.de/\">lxml</a> and <a\n",
      "href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</ol>\n",
      "\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "<p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "\n",
      "<h3>Getting and giving support</h3>\n",
      "\n",
      "<div id=\"tidelift\" align=\"center\">\n",
      "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise\" target=\"_blank\">\n",
      " <span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>\n",
      "</div>\n",
      "\n",
      "<p>If you have questions, send them to <a\n",
      "href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
      "\n",
      "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
      "</div>\n",
      "\n",
      "\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.11.2</a> (January 31, 2023). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "<p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "<p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "<p>Beautiful Soup 4 works on Python 3.6 and up. Support for Python 2 was discontinued on January 1,\n",
      "2021&mdash;one year after the Python 2 sunsetting date.\n",
      "\n",
      "<h3>Beautiful Soup 3</h3>\n",
      "\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and was\n",
      "discontinued or January 1, 2021&mdash;one year after the Python 2\n",
      "sunsetting date. If you have any active projects using Beautiful Soup\n",
      "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
      "conversion.\n",
      "\n",
      "<p><a\n",
      "href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "\n",
      "<p>The current and hopefully final release of Beautiful Soup 3 is <a\n",
      "href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "<ul>\n",
      "\n",
      "<li><a\n",
      " href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "<li>Jiabao Lin's <a\n",
      "href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\n",
      "uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n",
      "\n",
      "<li>Reddit uses Beautiful Soup to <a\n",
      "href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a\n",
      " href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "<li>The developers of Python itself used Beautiful Soup to <a\n",
      "href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <A\n",
      "href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a\n",
      "href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</ul>\n",
      "\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a\n",
      "href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "<h2>Development</h2>\n",
      "\n",
      "<p>Development happens at <a\n",
      "href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a\n",
      "href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.<hr><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Tuesday, January 31 2023, 18:01:14 Nowhere Standard Time and last built on Friday, February 24 2023, 09:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"></a></td><td valign=\"top\">Crummy is &copy; 1996-2023 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></span><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=top><p><b>Document tree:</b>\n",
      "<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dl>\n",
      "</dl>\n",
      "</dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form method=\"get\" action=\"/search/\">\n",
      "        <input type=\"text\" name=\"q\" maxlength=\"255\" value=\"\"></input>\n",
      "        </form>\n",
      "        </td>\n",
      "\n",
      "</tr>\n",
      "\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://www.crummy.com/software/BeautifulSoup/'\n",
    "source = urlopen(url).read().decode('utf-8') # read in html and decode bytes into string\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraped contents of the url are just a string so you can use all of the python string manipulation methods you're familiar with like find(), count() and replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "## count occurences of 'Soup'\n",
    "print(type(source))\n",
    "print(source.count('Soup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7608\n"
     ]
    }
   ],
   "source": [
    "## find index of 'Reddit uses Beautiful Soup'\n",
    "position =  source.find('Reddit uses Beautiful Soup')\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit uses Beautiful Soup\n"
     ]
    }
   ],
   "source": [
    "# test to see the substring\n",
    "print(source[position:position + len('Reddit uses Beautiful Soup')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n",
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<style>\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "</style>\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "</div>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "</p><ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "</li><li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "</p><h3>Getting and giving support</h3>\n",
      "<div align=\"center\" id=\"tidelift\">\n",
      "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "<span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>\n",
      "</div>\n",
      "<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
      "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "</p><p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.11.2</a> (January 31, 2023). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "</p><p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "</p><p>Beautiful Soup 4 works on Python 3.6 and up. Support for Python 2 was discontinued on January 1,\n",
      "2021—one year after the Python 2 sunsetting date.\n",
      "\n",
      "</p><h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and was\n",
      "discontinued or January 1, 2021—one year after the Python 2\n",
      "sunsetting date. If you have any active projects using Beautiful Soup\n",
      "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
      "conversion.\n",
      "\n",
      "</p><p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "</p><p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "</p><p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "</p><p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "</p><ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "</li><li>Jiabao Lin's <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\n",
      "uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n",
      "\n",
      "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "</p><h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Tuesday, January 31 2023, 18:01:14 Nowhere Standard Time and last built on Friday, February 24 2023, 09:00:01 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2023 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
      "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
      "</dd></dl>\n",
      "</dd></dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form action=\"/search/\" method=\"get\">\n",
      "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "</form>\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4 #this is beautiful soup\n",
    "\n",
    "soup = bs4.BeautifulSoup(source, \"lxml\") # lxml is the parser library\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <style>\n",
      "   #tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "  </style>\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   [\n",
      "   <a href=\"#Download\">\n",
      "    Download\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Documentation\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"#HallOfFame\">\n",
      "    Hall of Fame\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"enterprise.html\">\n",
      "    For enterprise\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "    Source\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">\n",
      "    Changelog\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    Discussion group\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"zine/\">\n",
      "    Zine\n",
      "   </a>\n",
      "   ]\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "  </p>\n",
      "  <ol>\n",
      "   <li>\n",
      "    Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup sits on top of popular Python parsers like\n",
      "    <a href=\"http://lxml.de/\">\n",
      "     lxml\n",
      "    </a>\n",
      "    and\n",
      "    <a href=\"http://code.google.com/p/html5lib/\">\n",
      "     html5lib\n",
      "    </a>\n",
      "    , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "   </li>\n",
      "  </ol>\n",
      "  <p>\n",
      "   Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "   <tt>\n",
      "    externalLink\n",
      "   </tt>\n",
      "   \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Interested?\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Read more.\n",
      "   </a>\n",
      "  </p>\n",
      "  <h3>\n",
      "   Getting and giving support\n",
      "  </h3>\n",
      "  <div align=\"center\" id=\"tidelift\">\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "    <span class=\"cta\">\n",
      "     Beautiful Soup for enterprise available via Tidelift\n",
      "    </span>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   If you have questions, send them to\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   . If you find a bug,\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file it on Launchpad\n",
      "   </a>\n",
      "   . If it's a security vulnerability, report it confidentially through\n",
      "   <a href=\"https://tidelift.com/security\">\n",
      "    Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   If you use Beautiful Soup as part of your work, please consider a\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    Tidelift subscription\n",
      "   </a>\n",
      "   . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "   <a href=\"zine/\">\n",
      "    <i>\n",
      "     Tool Safety\n",
      "    </i>\n",
      "   </a>\n",
      "   , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "  </p>\n",
      "  <a name=\"Download\">\n",
      "   <h2>\n",
      "    Download Beautiful Soup\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   The current release is\n",
      "   <a href=\"bs4/download/\">\n",
      "    Beautiful Soup\n",
      "4.11.2\n",
      "   </a>\n",
      "   (January 31, 2023). You can install Beautiful Soup 4 with\n",
      "   <code>\n",
      "    pip install beautifulsoup4\n",
      "   </code>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "   <code>\n",
      "    python-bs4\n",
      "   </code>\n",
      "   package (for Python 2) or the\n",
      "   <code>\n",
      "    python3-bs4\n",
      "   </code>\n",
      "   package (for Python 3). In Fedora it's\n",
      "available as the\n",
      "   <code>\n",
      "    python-beautifulsoup4\n",
      "   </code>\n",
      "   package.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "   <code>\n",
      "    bs4/\n",
      "   </code>\n",
      "   directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "   <code>\n",
      "    2to3\n",
      "   </code>\n",
      "   .)\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 4 works on Python 3.6 and up. Support for Python 2 was discontinued on January 1,\n",
      "2021—one year after the Python 2 sunsetting date.\n",
      "  </p>\n",
      "  <h3>\n",
      "   Beautiful Soup 3\n",
      "  </h3>\n",
      "  <p>\n",
      "   Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and was\n",
      "discontinued or January 1, 2021—one year after the Python 2\n",
      "sunsetting date. If you have any active projects using Beautiful Soup\n",
      "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
      "conversion.\n",
      "  </p>\n",
      "  <p>\n",
      "   <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "    Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   The current and hopefully final release of Beautiful Soup 3 is\n",
      "   <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\n",
      "    3.2.2\n",
      "   </a>\n",
      "   (October 5,\n",
      "2019). It's the\n",
      "   <code>\n",
      "    BeautifulSoup\n",
      "   </code>\n",
      "   package on pip. It's also\n",
      "available as\n",
      "   <code>\n",
      "    python-beautifulsoup\n",
      "   </code>\n",
      "   in Debian and Ubuntu,\n",
      "and as\n",
      "   <code>\n",
      "    python-BeautifulSoup\n",
      "   </code>\n",
      "   in Fedora.\n",
      "  </p>\n",
      "  <p>\n",
      "   Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 3, like Beautiful Soup 4, is\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    supported through Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <a name=\"HallOfFame\">\n",
      "   <h2>\n",
      "    Hall of Fame\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "  </p>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "     \"Movable\n",
      " Type\"\n",
      "    </a>\n",
      "    , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "   </li>\n",
      "   <li>\n",
      "    Jiabao Lin's\n",
      "    <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">\n",
      "     DXY-COVID-19-Crawler\n",
      "    </a>\n",
      "    uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source:\n",
      "    <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\n",
      "     \"How open source software is fighting COVID-19\"\n",
      "    </a>\n",
      "    )\n",
      "   </li>\n",
      "   <li>\n",
      "    Reddit uses Beautiful Soup to\n",
      "    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "     parse\n",
      "a page that's been linked to and find a representative image\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    Alexander Harrowell uses Beautiful Soup to\n",
      "    <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "     track the business\n",
      " activities\n",
      "    </a>\n",
      "    of an arms merchant.\n",
      "   </li>\n",
      "   <li>\n",
      "    The developers of Python itself used Beautiful Soup to\n",
      "    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://www2.ljworld.com/\">\n",
      "     Lawrence Journal-World\n",
      "    </a>\n",
      "    uses Beautiful Soup to\n",
      "    <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "     gather\n",
      "statewide election results\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "     NOAA's Forecast\n",
      "Applications Branch\n",
      "    </a>\n",
      "    uses Beautiful Soup in\n",
      "    <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "     TopoGrabber\n",
      "    </a>\n",
      "    , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "   </li>\n",
      "  </ul>\n",
      "  <p>\n",
      "   If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "   <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <h2>\n",
      "   Development\n",
      "  </h2>\n",
      "  <p>\n",
      "   Development happens at\n",
      "   <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "    Launchpad\n",
      "   </a>\n",
      "   . You can\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "    get the source\n",
      "code\n",
      "   </a>\n",
      "   or\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file\n",
      "bugs\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <table>\n",
      "   <tr>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      This document (\n",
      "      <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "       source\n",
      "      </a>\n",
      "      ) is part of Crummy, the webspace of\n",
      "      <a href=\"/self/\">\n",
      "       Leonard Richardson\n",
      "      </a>\n",
      "      (\n",
      "      <a href=\"/self/contact.html\">\n",
      "       contact information\n",
      "      </a>\n",
      "      ). It was last modified on Tuesday, January 31 2023, 18:01:14 Nowhere Standard Time and last built on Friday, February 24 2023, 09:00:01 Nowhere Standard Time.\n",
      "     </p>\n",
      "     <p>\n",
      "     </p>\n",
      "     <table class=\"licenseText\">\n",
      "      <tr>\n",
      "       <td>\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "        </a>\n",
      "       </td>\n",
      "       <td valign=\"top\">\n",
      "        Crummy is © 1996-2023 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         Creative Commons License\n",
      "        </a>\n",
      "        .\n",
      "       </td>\n",
      "      </tr>\n",
      "     </table>\n",
      "     <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "    </td>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      <b>\n",
      "       Document tree:\n",
      "      </b>\n",
      "     </p>\n",
      "     <dl>\n",
      "      <dd>\n",
      "       <a href=\"http://www.crummy.com/\">\n",
      "        http://www.crummy.com/\n",
      "       </a>\n",
      "       <dl>\n",
      "        <dd>\n",
      "         <a href=\"http://www.crummy.com/software/\">\n",
      "          software/\n",
      "         </a>\n",
      "         <dl>\n",
      "          <dd>\n",
      "           <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "            BeautifulSoup/\n",
      "           </a>\n",
      "          </dd>\n",
      "         </dl>\n",
      "        </dd>\n",
      "       </dl>\n",
      "      </dd>\n",
      "     </dl>\n",
      "     Site Search:\n",
      "     <form action=\"/search/\" method=\"get\">\n",
      "      <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "     </form>\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<h1>Beautiful Soup</h1>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = soup.find('h1') # or .find_all() to get a list of all h1 headers\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Beautiful Soup'"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">How would I extract just the first paragraph?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<a href=\"#Download\">Download</a>,\n <a href=\"bs4/doc/\">Documentation</a>,\n <a href=\"#HallOfFame\">Hall of Fame</a>,\n <a href=\"enterprise.html\">For enterprise</a>,\n <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a>,\n <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a>,\n <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>,\n <a href=\"zine/\">Zine</a>,\n <a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>,\n <a href=\"http://lxml.de/\">lxml</a>,\n <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>,\n <a href=\"bs4/doc/\">Read more.</a>,\n <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n <span class=\"cta\">\n   Beautiful Soup for enterprise available via Tidelift\n  </span>\n </a>,\n <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n group</a>,\n <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>,\n <a href=\"https://tidelift.com/security\">Tidelift</a>,\n <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>,\n <a href=\"zine/\"><i>Tool Safety</i></a>,\n <a name=\"Download\"><h2>Download Beautiful Soup</h2></a>,\n <a href=\"bs4/download/\">Beautiful Soup\n 4.11.2</a>,\n <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n the Beautiful Soup 3 documentation.</a>,\n <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a>,\n <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>,\n <a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>,\n <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n  Type\"</a>,\n <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>,\n <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>,\n <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n a page that's been linked to and find a representative image</a>,\n <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n  activities</a>,\n <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n bug tracker from Sourceforge to Roundup</a>,\n <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>,\n <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n statewide election results</a>,\n <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n Applications Branch</a>,\n <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>,\n <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n group</a>,\n <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>,\n <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n code</a>,\n <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n bugs</a>,\n <a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>,\n <a href=\"/self/\">Leonard Richardson</a>,\n <a href=\"/self/contact.html\">contact information</a>,\n <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a>,\n <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>,\n <a href=\"http://www.crummy.com/\">http://www.crummy.com/</a>,\n <a href=\"http://www.crummy.com/software/\">software/</a>,\n <a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a>]"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to find all of a tag\n",
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://code.google.com/p/html5lib/\">html5lib</a>\n"
     ]
    },
    {
     "data": {
      "text/plain": "'http://code.google.com/p/html5lib/'"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "a_link = links[10]\n",
    "print(a_link)\n",
    "a_link.get('href') # search within one tag for a specific attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['#Download',\n 'bs4/doc/',\n '#HallOfFame',\n 'enterprise.html',\n 'https://code.launchpad.net/beautifulsoup',\n 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'zine/',\n 'bs4/download/',\n 'http://lxml.de/',\n 'http://code.google.com/p/html5lib/',\n 'bs4/doc/',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'https://bugs.launchpad.net/beautifulsoup/',\n 'https://tidelift.com/security',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n 'zine/',\n None,\n 'bs4/download/',\n 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n 'download/3.x/BeautifulSoup-3.2.2.tar.gz',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n None,\n 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n 'http://www.harrowell.org.uk/viktormap.html',\n 'http://svn.python.org/view/tracker/importer/',\n 'http://www2.ljworld.com/',\n 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n 'http://esrl.noaa.gov/gsd/fab/',\n 'http://laps.noaa.gov/topograbber/',\n 'http://groups.google.com/group/beautifulsoup/',\n 'https://launchpad.net/beautifulsoup',\n 'https://code.launchpad.net/beautifulsoup/',\n 'https://bugs.launchpad.net/beautifulsoup/',\n '/source/software/BeautifulSoup/index.bhtml',\n '/self/',\n '/self/contact.html',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://www.crummy.com/',\n 'http://www.crummy.com/software/',\n 'http://www.crummy.com/software/BeautifulSoup/']"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store all links on the page in a list\n",
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://code.launchpad.net/beautifulsoup',\n 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'http://lxml.de/',\n 'http://code.google.com/p/html5lib/',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'https://bugs.launchpad.net/beautifulsoup/',\n 'https://tidelift.com/security',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n 'http://www.harrowell.org.uk/viktormap.html',\n 'http://svn.python.org/view/tracker/importer/',\n 'http://www2.ljworld.com/',\n 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n 'http://esrl.noaa.gov/gsd/fab/',\n 'http://laps.noaa.gov/topograbber/',\n 'http://groups.google.com/group/beautifulsoup/',\n 'https://launchpad.net/beautifulsoup',\n 'https://code.launchpad.net/beautifulsoup/',\n 'https://bugs.launchpad.net/beautifulsoup/',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://www.crummy.com/',\n 'http://www.crummy.com/software/',\n 'http://www.crummy.com/software/BeautifulSoup/']"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all external links\n",
    "external_links = []\n",
    "\n",
    "# the loop filters out \"None\" and links that don't start with http\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n",
    "external_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['https://code.launchpad.net/beautifulsoup',\n 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'http://lxml.de/',\n 'http://code.google.com/p/html5lib/',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n 'https://bugs.launchpad.net/beautifulsoup/',\n 'https://tidelift.com/security',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n 'http://www.harrowell.org.uk/viktormap.html',\n 'http://svn.python.org/view/tracker/importer/',\n 'http://www2.ljworld.com/',\n 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n 'http://esrl.noaa.gov/gsd/fab/',\n 'http://laps.noaa.gov/topograbber/',\n 'http://groups.google.com/group/beautifulsoup/',\n 'https://launchpad.net/beautifulsoup',\n 'https://code.launchpad.net/beautifulsoup/',\n 'https://bugs.launchpad.net/beautifulsoup/',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://creativecommons.org/licenses/by-sa/2.0/',\n 'http://www.crummy.com/',\n 'http://www.crummy.com/software/',\n 'http://www.crummy.com/software/BeautifulSoup/']"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same this using list comprehension\n",
    "\n",
    "[l for l in link_list if l is not None and l.startswith('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping dynamic webpages using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe src=https://www.worldometers.info/coronavirus/weekly-trends/ width=1000 height=400></iframe>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "HTML('<iframe src=https://www.worldometers.info/coronavirus/weekly-trends/ width=1000 height=400></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we need information on the weekly case/death change? - Our robot must click on the Columns dropdown menu and select the required columns. We need another package called Selenium to this end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (4.2.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.9.24)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "#from selenium.webdriver.common.by import By\n",
    "#from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 110.0.5481\n",
      "[WDM] - Get LATEST chromedriver version for 110.0.5481 google-chrome\n",
      "[WDM] - There is no [win32] chromedriver for browser 110.0.5481 in cache\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/110.0.5481.77/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\rahul\\.wdm\\drivers\\chromedriver\\win32\\110.0.5481.77]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get('https://www.worldometers.info/coronavirus/weekly-trends/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this doesn't work for you, heres another way to open the website. You'll first have to install a Web Driver, for example Google Chrome:\n",
    "\n",
    "https://chromedriver.chromium.org/downloads \n",
    "\n",
    "Make sure to download the version that matches the current version of your chrome browser! Store the webdriver .exe file somewhere you can access it with a relative file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\common\\service.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[0mcmd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcommand_line_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 71\u001B[1;33m             self.process = subprocess.Popen(cmd, env=self.env,\n\u001B[0m\u001B[0;32m     72\u001B[0m                                             \u001B[0mclose_fds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msystem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m'Windows'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001B[0m\n\u001B[0;32m    950\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 951\u001B[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001B[0m\u001B[0;32m    952\u001B[0m                                 \u001B[0mpass_fds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcwd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001B[0m in \u001B[0;36m_execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001B[0m\n\u001B[0;32m   1419\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1420\u001B[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001B[0m\u001B[0;32m   1421\u001B[0m                                          \u001B[1;31m# no special security\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mWebDriverException\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\3730492576.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdriver\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwebdriver\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mChrome\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../Data/chromedriver/chromedriver'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# chromedriver is an .exe file, depending on your computer you may have to specify this file extension\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdriver\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'https://www.worldometers.info/coronavirus/weekly-trends/'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[0mservice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mService\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexecutable_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mport\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mservice_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mservice_log_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m         super(WebDriver, self).__init__(DesiredCapabilities.CHROME['browserName'], \"goog\",\n\u001B[0m\u001B[0;32m     71\u001B[0m                                         \u001B[0mport\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m                                         \u001B[0mservice_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdesired_capabilities\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mservice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\common\\service.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     79\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrno\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0merrno\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mENOENT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m                 raise WebDriverException(\n\u001B[0m\u001B[0;32m     82\u001B[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001B[0;32m     83\u001B[0m                         os.path.basename(self.path), self.start_error_message)\n",
      "\u001B[1;31mWebDriverException\u001B[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "driver = webdriver.Chrome('../Data/chromedriver/chromedriver') # chromedriver is an .exe file, depending on your computer you may have to specify this file extension\n",
    "driver.get('https://www.worldometers.info/coronavirus/weekly-trends/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the dropdown menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "element = driver.find_element(By.CLASS_NAME,'dropdown-toggle')\n",
    "print(element.text) # '.text' identifies whats on the website so check to make sure it's right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Click on the dropdown menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button title=\"Click to hide/show columns\" style=\"margin-top:-2px;font-size:14px;\" class=\"btn btn-sm btn-secondary dropdown-toggle\" type=\"button\" data-toggle=\"dropdown\" aria-haspopup=\"true\" aria-expanded=\"false\">...</button> is not clickable at point (314, 771). Other element would receive the click: <iframe id=\"aswift_3\" name=\"aswift_3\" style=\"width: 1005px !important; height: 124px !important; display: block; margin: 0px auto;\" sandbox=\"allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation\" width=\"1005\" height=\"124\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" vspace=\"0\" hspace=\"0\" allowtransparency=\"true\" scrolling=\"no\" src=\"https://googleads.g.doubleclick.net/pagead/html/r20230222/r20110914/zrt_lookup.html?fsb=1#RS-1-&amp;adk=1812271801&amp;client=ca-pub-3701697624350410&amp;fa=1&amp;ifi=4&amp;uci=a!4&amp;btvi=2&amp;xpc=laI7C1z2K9&amp;p=https%3A//www.worldometers.info\" data-google-container-id=\"a!4\" data-google-query-id=\"CO7V--Plrf0CFcYfBgAd7QsD7Q\" data-load-complete=\"true\"></iframe>\n  (Session info: chrome=110.0.5481.104)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x005937D3]\n\t(No symbol) [0x00528B81]\n\t(No symbol) [0x0042B36D]\n\t(No symbol) [0x00464E3B]\n\t(No symbol) [0x004626DB]\n\t(No symbol) [0x0045FD0B]\n\t(No symbol) [0x0045E4D8]\n\t(No symbol) [0x00453253]\n\t(No symbol) [0x0047B41C]\n\t(No symbol) [0x00452B96]\n\t(No symbol) [0x0047B774]\n\t(No symbol) [0x00491215]\n\t(No symbol) [0x0047B216]\n\t(No symbol) [0x00450D97]\n\t(No symbol) [0x0045253D]\n\tGetHandleVerifier [0x0080ABF2+2510930]\n\tGetHandleVerifier [0x00838EC1+2700065]\n\tGetHandleVerifier [0x0083C86C+2714828]\n\tGetHandleVerifier [0x00643480+645344]\n\t(No symbol) [0x00530FD2]\n\t(No symbol) [0x00536C68]\n\t(No symbol) [0x00536D4B]\n\t(No symbol) [0x00540D6B]\n\tBaseThreadInitThunk [0x77697D69+25]\n\tRtlInitializeExceptionChain [0x77DFBB9B+107]\n\tRtlClearBits [0x77DFBB1F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mElementClickInterceptedException\u001B[0m          Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_50764\\1111478089.py\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# pause to ensure that the website has fully opened, sometimes selenium is too fast\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0melement\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclick\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001B[0m in \u001B[0;36mclick\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclick\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[1;34m\"\"\"Clicks the element.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_execute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCommand\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCLICK_ELEMENT\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0msubmit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001B[0m in \u001B[0;36m_execute\u001B[1;34m(self, command, params)\u001B[0m\n\u001B[0;32m    771\u001B[0m             \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    772\u001B[0m         \u001B[0mparams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'id'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_id\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 773\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parent\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    774\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    775\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfind_element\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mby\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mBy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mID\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, driver_command, params)\u001B[0m\n\u001B[0;32m    428\u001B[0m         \u001B[0mresponse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcommand_executor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdriver_command\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 430\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_response\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    431\u001B[0m             response['value'] = self._unwrap_value(\n\u001B[0;32m    432\u001B[0m                 response.get('value', None))\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001B[0m in \u001B[0;36mcheck_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    245\u001B[0m                 \u001B[0malert_text\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'alert'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'text'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    246\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mexception_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscreen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstacktrace\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malert_text\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 247\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mexception_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscreen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstacktrace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    248\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    249\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_value_or_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mMapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0m_KT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_VT\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m_KT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdefault\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0m_VT\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0m_VT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mElementClickInterceptedException\u001B[0m: Message: element click intercepted: Element <button title=\"Click to hide/show columns\" style=\"margin-top:-2px;font-size:14px;\" class=\"btn btn-sm btn-secondary dropdown-toggle\" type=\"button\" data-toggle=\"dropdown\" aria-haspopup=\"true\" aria-expanded=\"false\">...</button> is not clickable at point (314, 771). Other element would receive the click: <iframe id=\"aswift_3\" name=\"aswift_3\" style=\"width: 1005px !important; height: 124px !important; display: block; margin: 0px auto;\" sandbox=\"allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation\" width=\"1005\" height=\"124\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" vspace=\"0\" hspace=\"0\" allowtransparency=\"true\" scrolling=\"no\" src=\"https://googleads.g.doubleclick.net/pagead/html/r20230222/r20110914/zrt_lookup.html?fsb=1#RS-1-&amp;adk=1812271801&amp;client=ca-pub-3701697624350410&amp;fa=1&amp;ifi=4&amp;uci=a!4&amp;btvi=2&amp;xpc=laI7C1z2K9&amp;p=https%3A//www.worldometers.info\" data-google-container-id=\"a!4\" data-google-query-id=\"CO7V--Plrf0CFcYfBgAd7QsD7Q\" data-load-complete=\"true\"></iframe>\n  (Session info: chrome=110.0.5481.104)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x005937D3]\n\t(No symbol) [0x00528B81]\n\t(No symbol) [0x0042B36D]\n\t(No symbol) [0x00464E3B]\n\t(No symbol) [0x004626DB]\n\t(No symbol) [0x0045FD0B]\n\t(No symbol) [0x0045E4D8]\n\t(No symbol) [0x00453253]\n\t(No symbol) [0x0047B41C]\n\t(No symbol) [0x00452B96]\n\t(No symbol) [0x0047B774]\n\t(No symbol) [0x00491215]\n\t(No symbol) [0x0047B216]\n\t(No symbol) [0x00450D97]\n\t(No symbol) [0x0045253D]\n\tGetHandleVerifier [0x0080ABF2+2510930]\n\tGetHandleVerifier [0x00838EC1+2700065]\n\tGetHandleVerifier [0x0083C86C+2714828]\n\tGetHandleVerifier [0x00643480+645344]\n\t(No symbol) [0x00530FD2]\n\t(No symbol) [0x00536C68]\n\t(No symbol) [0x00536D4B]\n\t(No symbol) [0x00540D6B]\n\tBaseThreadInitThunk [0x77697D69+25]\n\tRtlInitializeExceptionChain [0x77DFBB9B+107]\n\tRtlClearBits [0x77DFBB1F+191]\n"
     ]
    }
   ],
   "source": [
    "element = driver.find_element(By.CLASS_NAME,'dropdown-toggle')\n",
    "\n",
    "time.sleep(2) # pause to ensure that the website has fully opened, sometimes selenium is too fast\n",
    "element.click()\n",
    "time.sleep(2)\n",
    "\n",
    "element = driver.find_element(By.ID,'colsDrop')\n",
    "element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.get_attribute('innerHTML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Click the checkboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element1 = element.find_element(By.ID, 'column_11')\n",
    "element2 = element.find_element(By.ID, 'column_13')\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", element1)\n",
    "driver.execute_script(\"arguments[0].click();\", element2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Download the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_after = driver.window_handles[-1] #Change the current window to the latest one opened if necessary \n",
    "driver.switch_to.window(window_after)\n",
    "\n",
    "source = driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a pandas data frame with the countires and their weekly case change and death change. Let's process the html source / data with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments: tag, {attribute: value}\n",
    "table = soup.find('table', {'id':'main_table_countries_today'})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all('tr', {'role':'row'})\n",
    "rows[0] # use .text to understand what part of the site it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=[]\n",
    "\n",
    "for row in rows:\n",
    "    countries.append(row.find('a', {'class':'mt_a'}))\n",
    "    \n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=list(filter(lambda x: x != None, countries))\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(countries)):\n",
    "    countries[row] = countries[row].text\n",
    "    \n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which other columns do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x.text, rows[0].find_all('th'))) # map() applies a function to each element of an iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=table.find_all('tr', {'role':'row'})\n",
    "countries=[]\n",
    "weekly_case_change=[]\n",
    "weekly_death_change=[]\n",
    "\n",
    "for row in rows:\n",
    "    try:\n",
    "        countries.append(row.find('a', {'class':'mt_a'}).text)\n",
    "        weekly_case_change.append(row.find_all('td')[-4].text)\n",
    "        weekly_death_change.append(row.find_all('td')[-3].text)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Countries':countries, 'Weekly_Case_Change':weekly_case_change, 'Weekly_Death_Change':weekly_death_change})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekly_Case_Change']=df['Weekly_Case_Change'].apply(lambda x: float(x.replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekly_Death_Change']=df['Weekly_Death_Change'].apply(lambda x: float(x.replace(',','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: Don't scrape the data from the website over and over (server overload), instead save a datafile to your personal computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Data/covid_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/covid_scrape.csv')\n",
    "df.drop(labels=['Unnamed: 0.1','Unnamed: 0'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Weekly_Case_Change', ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.barh(df.Countries[0:5], df.Weekly_Case_Change[0:5])\n",
    "plt.xlabel('Weekly_Case_Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Weekly_Death_Change', ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.barh(df.head().Countries, df.head().Weekly_Death_Change)\n",
    "plt.xlabel('Weekly_Death_Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.scatter(df.Weekly_Case_Change, df.Weekly_Death_Change)\n",
    "plt.xlabel('Weekly Case Change')\n",
    "plt.ylabel('Weekly Death Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.scatter(df.Weekly_Case_Change, df.Weekly_Death_Change)\n",
    "plt.xlabel('Weekly Case Change')\n",
    "plt.ylabel('Weekly Death Change')\n",
    "plt.xlim([-1000, 1000])\n",
    "plt.ylim([-50, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
